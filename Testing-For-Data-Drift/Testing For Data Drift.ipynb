{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29adb36d-8a5e-49e7-a9a7-5de28bb5c43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81326cb5-972f-4291-b23e-eafae9d4f09f",
   "metadata": {},
   "source": [
    "Certainly! To ensure that the sample data of your trained model has not significantly changed from the new collected test data, you can use statistical tests to compare the distributions of the features in both datasets. A common approach is to use the Kolmogorov-Smirnov (KS) test or the Chi-square test for categorical data. Here, I'll provide an example using the KS test for continuous features.\n",
    "\n",
    "Explanation\n",
    "Kolmogorov-Smirnov Test: This non-parametric test compares the distributions of two samples to determine if they differ significantly. It is useful for continuous data and does not assume any specific distribution.\n",
    "\n",
    "Chi-Square Test: This test compares the distribution of categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aff3dd8-e9e3-40c5-8440-82500e183945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20dec9f-84e7-450f-ae20-074ebbda0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(train_data: pd.DataFrame, test_data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compares the distributions of the features in the training data with the test data.\n",
    "\n",
    "    Args:\n",
    "        train_data: DataFrame containing the training data.\n",
    "        test_data: DataFrame containing the test data.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with the test results.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for column in train_data.columns:\n",
    "        if train_data[column].dtype in [np.float64, np.float32, np.int64, np.int32]:  # Continuous data\n",
    "            # Perform KS test\n",
    "            stat, p_value = ks_2samp(train_data[column], test_data[column])\n",
    "            results[column] = {'test': 'KS', 'statistic': stat, 'p_value': p_value}\n",
    "        else:  # Categorical data\n",
    "            # Perform Chi-square test\n",
    "            contingency_table = pd.crosstab(train_data[column], test_data[column])\n",
    "            stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "            results[column] = {'test': 'Chi-square', 'statistic': stat, 'p_value': p_value}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a4d62a9-b486-433d-9843-6bf3c4de6ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: age\n",
      "Test: KS\n",
      "Statistic: 0.063\n",
      "P-value: 0.509500976763525\n",
      "\n",
      "\n",
      "Feature: income\n",
      "Test: KS\n",
      "Statistic: 0.117\n",
      "P-value: 0.01969347905750255\n",
      "\n",
      "\n",
      "Feature: gender\n",
      "Test: Chi-square\n",
      "Statistic: 0.08082677910530667\n",
      "P-value: 0.7761800965260952\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Assuming `train_df` is your training data and `test_df` is your new collected test data\n",
    "train_df = pd.DataFrame({\n",
    "    'age': np.random.randint(20, 60, 1000),\n",
    "    'income': np.random.normal(50000, 15000, 1000),\n",
    "    'gender': np.random.choice(['M', 'F'], 1000)\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'age': np.random.randint(20, 60, 200),\n",
    "    'income': np.random.normal(51000, 15500, 200),\n",
    "    'gender': np.random.choice(['M', 'F'], 200)\n",
    "})\n",
    "\n",
    "results = compare_distributions(train_df, test_df)\n",
    "\n",
    "# Display the results\n",
    "for feature, result in results.items():\n",
    "    print(f\"Feature: {feature}\")\n",
    "    print(f\"Test: {result['test']}\")\n",
    "    print(f\"Statistic: {result['statistic']}\")\n",
    "    print(f\"P-value: {result['p_value']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90229b-a9e6-4e95-a07f-207c6e092fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a274a61-dee4-44c4-9e2f-83d9bec08181",
   "metadata": {},
   "source": [
    "#### Interpretation of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf727533-d31e-434d-90cb-8b482fed2750",
   "metadata": {},
   "source": [
    "##### P-value: \n",
    "        The p-value indicates the probability that the observed difference between the distributions happened by chance. A low p-value (typically < 0.05) suggests a significant difference between the distributions.\n",
    "Statistic: The test statistic gives a measure of the difference between the distributions.\n",
    "This approach ensures that you can statistically compare the distributions of your features between the training and new test data, helping you detect any significant changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ebf492-4e0e-4b2d-83e9-0306efad7e1c",
   "metadata": {},
   "source": [
    "#### Load the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a03d2661-3c7a-4b3c-a673-876b96dc279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex   age  sibsp  parch      fare embarked  class  \\\n",
      "779         1       1  female  43.0      0      1  211.3375        S  First   \n",
      "741         0       1    male  36.0      1      0   78.8500        S  First   \n",
      "540         1       1  female  36.0      0      2   71.0000        S  First   \n",
      "716         1       1  female  38.0      0      0  227.5250        C  First   \n",
      "151         1       1  female  22.0      1      0   66.6000        S  First   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "779  woman       False    B  Southampton   yes  False  \n",
      "741    man        True    C  Southampton    no  False  \n",
      "540  woman       False    B  Southampton   yes  False  \n",
      "716  woman       False    C    Cherbourg   yes   True  \n",
      "151  woman       False    C  Southampton   yes  False  \n",
      "     survived  pclass     sex   age  sibsp  parch      fare embarked  class  \\\n",
      "118         0       1    male  24.0      0      1  247.5208        C  First   \n",
      "251         0       3  female  29.0      1      1   10.4625        S  Third   \n",
      "742         1       1  female  21.0      2      2  262.3750        C  First   \n",
      "496         1       1  female  54.0      1      0   78.2667        C  First   \n",
      "712         1       1    male  48.0      1      0   52.0000        S  First   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  \n",
      "118    man        True    B    Cherbourg    no  False  \n",
      "251  woman       False    G  Southampton    no  False  \n",
      "742  woman       False    B    Cherbourg   yes  False  \n",
      "496  woman       False    D    Cherbourg   yes  False  \n",
      "712    man        True    C  Southampton   yes  False  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic').dropna()\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece72ab5-9034-467d-9d21-f0c6e46e3540",
   "metadata": {},
   "source": [
    "#### Define Functions for Data Drift Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dfe45e-be9d-40dd-b223-4d1896959d14",
   "metadata": {},
   "source": [
    "##### Kolmogorov-Smirnov Test for Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "422c6418-ee7f-4c07-bde9-96fbd3932d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(train_data, test_data, feature_name):\n",
    "    ks_stat, p_value = ks_2samp(train_data[feature_name], test_data[feature_name])\n",
    "    return ks_stat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ec269-a0c2-40f7-91ef-e0a150505fde",
   "metadata": {},
   "source": [
    "##### Chi-Square Test for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63584367-a7ca-45de-b54f-c0ac6473ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square_test(train_data, test_data, feature_name):\n",
    "    contingency_table = pd.crosstab(train_data[feature_name], test_data[feature_name])\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "    return chi2, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48139677-b6d9-4960-8762-8ac5feb09470",
   "metadata": {},
   "source": [
    "##### Apply Population Stability Index (PSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb5fa0db-0b18-4d37-9405-a8df005e615c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: sepal length (cm)\n",
      "PSI Value: 0.5743322323195329\n",
      "Significant data drift detected (PSI >= 0.2).\n",
      "------------------------------\n",
      "Feature: sepal width (cm)\n",
      "PSI Value: 0.1458452581879954\n",
      "Moderate data drift detected (0.1 <= PSI < 0.2).\n",
      "------------------------------\n",
      "Feature: petal length (cm)\n",
      "PSI Value: 0.3418244382092846\n",
      "Significant data drift detected (PSI >= 0.2).\n",
      "------------------------------\n",
      "Feature: petal width (cm)\n",
      "PSI Value: 0.9391684203412669\n",
      "Significant data drift detected (PSI >= 0.2).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seune\\AppData\\Local\\Temp\\ipykernel_11228\\3793909051.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n"
     ]
    }
   ],
   "source": [
    "def calculate_psi(expected, actual, buckets=10):\n",
    "    def scale_range(input, min, max):\n",
    "        input += -(np.min(input))\n",
    "        input /= np.max(input) / (max - min)\n",
    "        input += min\n",
    "        return input\n",
    "    \n",
    "    breakpoints = np.arange(0, buckets + 1) / (buckets) * 100\n",
    "    \n",
    "    expected_percents = np.histogram(scale_range(expected, 0, 100), breakpoints)[0] / len(expected)\n",
    "    actual_percents = np.histogram(scale_range(actual, 0, 100), breakpoints)[0] / len(actual)\n",
    "    \n",
    "    def sub_psi(e_perc, a_perc):\n",
    "        if a_perc == 0:\n",
    "            a_perc = 0.0001\n",
    "        if e_perc == 0:\n",
    "            e_perc = 0.0001\n",
    "        return (e_perc - a_perc) * np.log(e_perc / a_perc)\n",
    "    \n",
    "    psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
    "    \n",
    "    return psi_value\n",
    "\n",
    "# Apply PSI to each feature\n",
    "for feature in df.columns:\n",
    "    psi_value = calculate_psi(train_df[feature], test_df[feature])\n",
    "    print(f'Feature: {feature}')\n",
    "    print(f'PSI Value: {psi_value}')\n",
    "    if psi_value >= 0.2:\n",
    "        print(\"Significant data drift detected (PSI >= 0.2).\")\n",
    "    elif psi_value >= 0.1:\n",
    "        print(\"Moderate data drift detected (0.1 <= PSI < 0.2).\")\n",
    "    else:\n",
    "        print(\"No significant data drift detected (PSI < 0.1).\")\n",
    "    print('-' * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da16821-ccb4-4f6a-b571-6d7d8db995d1",
   "metadata": {},
   "source": [
    "#### Apply Data Drift Detection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a9d9c5c-4c70-44a7-8f48-e43af04bd693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seune\\AppData\\Local\\Temp\\ipykernel_11228\\3793909051.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n",
      "C:\\Users\\seune\\AppData\\Local\\Temp\\ipykernel_11228\\3793909051.py:20: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  psi_value = np.sum(sub_psi(expected_percents[i], actual_percents[i]) for i in range(0, len(expected_percents)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Feature: survived\n",
      "KS Statistic: 0.10866141732283464, P-value: 0.7044749489139502\n",
      "PSI Value: 0.05252982491476137\n",
      "No significant data drift detected (PSI < 0.1)\n",
      "------------------------------\n",
      "Numerical Feature: pclass\n",
      "KS Statistic: 0.026628489620615606, P-value: 0.9999999999999742\n",
      "PSI Value: 0.01662110333819009\n",
      "No significant data drift detected (PSI < 0.1)\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No data; `observed` has size 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo significant data drift detected (PSI < 0.1)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# Apply Chi-Square test for categorical features\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     chi2_stat, chi2_p_value \u001b[38;5;241m=\u001b[39m chi_square_test(train_df, test_df, feature)\n\u001b[0;32m     21\u001b[0m     psi_value \u001b[38;5;241m=\u001b[39m calculate_psi(train_df[feature]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[0;32m     22\u001b[0m                               test_df[feature]\u001b[38;5;241m.\u001b[39mvalue_counts(normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCategorical Feature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m, in \u001b[0;36mchi_square_test\u001b[1;34m(train_data, test_data, feature_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchi_square_test\u001b[39m(train_data, test_data, feature_name):\n\u001b[0;32m      2\u001b[0m     contingency_table \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcrosstab(train_data[feature_name], test_data[feature_name])\n\u001b[1;32m----> 3\u001b[0m     chi2, p_value, _, _ \u001b[38;5;241m=\u001b[39m chi2_contingency(contingency_table)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chi2, p_value\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\scipy\\stats\\contingency.py:333\u001b[0m, in \u001b[0;36mchi2_contingency\u001b[1;34m(observed, correction, lambda_)\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll values in `observed` must be nonnegative.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data; `observed` has size 0.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    335\u001b[0m expected \u001b[38;5;241m=\u001b[39m expected_freq(observed)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(expected \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    337\u001b[0m     \u001b[38;5;66;03m# Include one of the positions where expected is zero in\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;66;03m# the exception message.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: No data; `observed` has size 0."
     ]
    }
   ],
   "source": [
    "# Apply data drift detection to each feature\n",
    "for feature in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[feature]):\n",
    "        # Apply KS test for numerical features\n",
    "        ks_stat, p_value = ks_test(train_df, test_df, feature)\n",
    "        psi_value = calculate_psi(train_df[feature], test_df[feature])\n",
    "        print(f'Numerical Feature: {feature}')\n",
    "        print(f'KS Statistic: {ks_stat}, P-value: {p_value}')\n",
    "        print(f'PSI Value: {psi_value}')\n",
    "        if p_value < 0.05:\n",
    "            print(\"Data drift detected (KS test)\")\n",
    "        if psi_value >= 0.2:\n",
    "            print(\"Significant data drift detected (PSI >= 0.2)\")\n",
    "        elif psi_value >= 0.1:\n",
    "            print(\"Moderate data drift detected (0.1 <= PSI < 0.2)\")\n",
    "        else:\n",
    "            print(\"No significant data drift detected (PSI < 0.1)\")\n",
    "    else:\n",
    "        # Apply Chi-Square test for categorical features\n",
    "        chi2_stat, chi2_p_value = chi_square_test(train_df, test_df, feature)\n",
    "        psi_value = calculate_psi(train_df[feature].value_counts(normalize=True).values, \n",
    "                                  test_df[feature].value_counts(normalize=True).values)\n",
    "        print(f'Categorical Feature: {feature}')\n",
    "        print(f'Chi-Square Statistic: {chi2_stat}, P-value: {chi2_p_value}')\n",
    "        print(f'PSI Value: {psi_value}')\n",
    "        if chi2_p_value < 0.05:\n",
    "            print(\"Data drift detected (Chi-Square test)\")\n",
    "        if psi_value >= 0.2:\n",
    "            print(\"Significant data drift detected (PSI >= 0.2)\")\n",
    "        elif psi_value >= 0.1:\n",
    "            print(\"Moderate data drift detected (0.1 <= PSI < 0.2)\")\n",
    "        else:\n",
    "            print(\"No significant data drift detected (PSI < 0.1)\")\n",
    "    print('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c44775-77dd-4fd0-9e80-7e625355f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply KS test to each feature\n",
    "for feature in df.columns:\n",
    "    ks_stat, p_value = ks_test(train_df, test_df, feature)\n",
    "    print(f'Feature: {feature}')\n",
    "    print(f'KS Statistic: {ks_stat}')\n",
    "    print(f'P-value: {p_value}')\n",
    "    print(\"Data drift detected\" if p_value < 0.05 else \"No data drift detected\")\n",
    "    print('-' * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
